framework: torch
env: coverage
lambda: 0.95
kl_coeff: 0.5
kl_target: 0.01
clip_rewards: True
clip_param: 0.2
vf_clip_param: 250.0
vf_share_layers: False
vf_loss_coeff: 1.0e-4
entropy_coeff: 0.01
train_batch_size: 5000
rollout_fragment_length: 100
sgd_minibatch_size: 1000
num_sgd_iter: 5
num_workers: 16
num_envs_per_worker: 8
lr: 5.0e-4
gamma: 0.9
batch_mode: truncate_episodes
observation_filter: NoFilter
num_gpus: 1
model:
    custom_model: adversarial
    custom_action_dist: hom_multi_action
    custom_model_config:
        graph_layers: 1
        graph_tabs: 2
        graph_edge_features: 1
        
        # 16
        graph_features: 32
        cnn_filters: [[8, [4, 4], 2], [16, [4, 4], 2], [32, [3, 3], 2]]
        value_cnn_filters: [[8, [4, 4], 2], [16, [4, 4], 2], [32, [4, 4], 2]]
        value_cnn_compression: 128
        cnn_compression: 32
        
        relative: true
        activation: relu
        freeze_coop: False
        freeze_greedy: False
        freeze_coop_value: False
        freeze_greedy_value: False
        cnn_residual: False
        agent_split: 1
env_config:
    world_shape: [24, 24]
    state_size: 16
    collapse_state: False
    termination_no_new_coverage: 10
    max_episode_len: 288 # (24*24)/2
    n_agents: [1, 5]
    disabled_teams_step: [True, False]
    disabled_teams_comms: [True, False]
    map_mode: split_half_fixed
    reward_annealing: 0.0
    communication_range: 16.0
    ensure_connectivity: True
    reward_type: split_right
    episode_termination: early_right # early/fixed/default
    operation_mode: coop_only
    agents:
        coverage_radius: 1
        visibility_distance: 0
        map_update_radius: 100
        relative_coord_frame: True
evaluation_num_workers: 2
evaluation_interval: 1
evaluation_num_episodes: 10
evaluation_config:
    env_config:
        termination_no_new_coverage: -1
        max_episode_len: 288 # (24*24)/2
        episode_termination: default
        operation_mode: all
        ensure_connectivity: False
_use_trajectory_view_api: False
alternative_config:
    self_interested:
        env_config:
            operation_mode: greedy_only
            disabled_teams_step: [False, False]
            disabled_teams_comms: [False, False]
        model:
            custom_model_config:
                freeze_coop: True
                freeze_greedy: False
    re_adapt:
        env_config:
            operation_mode: coop_only
            disabled_teams_step: [False, False]
            disabled_teams_comms: [False, False]
        model:
            custom_model_config:
                freeze_coop: False
                freeze_greedy: True
